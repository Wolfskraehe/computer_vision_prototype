{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''loading video names into a list for easier access with absolute path,\n",
    "video names can be access by calling the index of the video_lst and will contain \n",
    "the current absolute path, asumes that the video folder is in the same folder as this file'''\n",
    "\n",
    "video_path = \"videos\"\n",
    "full_path = os.path.abspath(video_path)\n",
    "\n",
    "video_lst = []\n",
    "v_dir = os.listdir(full_path)\n",
    "for name in v_dir:\n",
    "    video_lst.append(full_path+'/'+name)\n",
    "print(video_lst[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video into memory\n",
    "cap = cv.VideoCapture(video_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Playing one video file'''\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    '''cv_waitkey() defines miliseconds between frames, higher values play the video slower\n",
    "    ord('q') defines a key to exit the video'''\n",
    "    cv.imshow('frame',frame)\n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release() #after release from memory the video needs to be recaptured\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f430325",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing background substraction with morphological noise reduction\n",
    "    opencv has KNN and MOG2 BGS build in'''\n",
    "\n",
    "cap = cv.VideoCapture(video_lst[0])\n",
    "backSub = cv.createBackgroundSubtractorKNN()\n",
    "#backSub = cv.createBackgroundSubtractorMOG2()\n",
    "\n",
    "#kernel for morphological noise reduction\n",
    "#cv.MORPH_ELLIPSE\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3));\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    fgMask = backSub.apply(frame)\n",
    "    fgMask = cv.morphologyEx(fgMask, cv.MORPH_OPEN, kernel);\n",
    "\n",
    "    #cv.imshow('Frame', frame)\n",
    "    cv.imshow('FG Mask', fgMask)\n",
    "    \n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daria - Euclidean Distance Tracker\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker types in opencv -> needs different version of opencv to run\n",
    "tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "\n",
    "tracker = tracker_types[1]\n",
    "\n",
    "if tracker == 'BOOSTING':\n",
    "    tracker = cv.legacy.TrackerBoosting_create()\n",
    "if tracker == 'MIL':\n",
    "    tracker = cv.TrackerMIL_create() \n",
    "if tracker == 'KCF':\n",
    "    tracker = cv.TrackerKCF_create() \n",
    "if tracker == 'TLD':\n",
    "    tracker = cv.legacy.TrackerTLD_create() \n",
    "if tracker == 'MEDIANFLOW':\n",
    "    tracker = cv.legacy.TrackerMedianFlow_create() \n",
    "# if tracker_type == 'GOTURN':\n",
    "#     tracker = cv.TrackerGOTURN_create()\n",
    "if tracker == 'MOSSE':\n",
    "    tracker = cv.legacy.TrackerMOSSE_create()\n",
    "if tracker == \"CSRT\":\n",
    "    tracker = cv.TrackerCSRT_create()\n",
    "\n",
    "print(f\"Current tracker type: {tracker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750879ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "# Compute the frame difference\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    diff_frames1 = cv.absdiff(next_frame, cur_frame)\n",
    "    # Absolute difference between current frame and previous frame\n",
    "    diff_frames2 = cv.absdiff(cur_frame, prev_frame)\n",
    "    # Return the result of bitwise 'AND' between the above two resultant images\n",
    "    #gives better result than simple substraction\n",
    "    return cv.bitwise_and(diff_frames1, diff_frames2)\n",
    "\n",
    "def get_frame(cap):\n",
    "    ret, frame = cap.read()\n",
    "    # Resize the image not needed\n",
    "    '''frame = cv.resize(frame, None, fx=scaling_factor,\n",
    "        fy=scaling_factor, interpolation=cv.INTER_AREA)'''\n",
    "    return frame\n",
    "\n",
    "#finds and draws contours over pixels if greater than threshold\n",
    "def construct_contours(frame, contour_threshold):\n",
    "    frame = cv.dilate(frame, (1,1), iterations=1)\n",
    "    contours, hierarchy = cv.findContours(frame, cv.RETR_TREE, \n",
    "                                           cv.CHAIN_APPROX_SIMPLE)\n",
    "    '''cv.drawContours(frame_th, contours=contours, contourIdx=-1, \n",
    "                     color=(0, 255, 0), thickness=2, lineType=cv.LINE_AA)'''\n",
    "    detections=[]\n",
    "    for contour in contours:\n",
    "      if cv.contourArea(contour) < contour_threshold:\n",
    "        continue\n",
    "      (x, y, w, h) = cv.boundingRect(contour)\n",
    "      #cv.rectangle(frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "      detections.append([x,y,w,h])\n",
    "    \n",
    "    return detections\n",
    "\n",
    "    #applying blur will possibly extend with other option for preperation\n",
    "def prepare_frames(frames,kernel):\n",
    "    result = []\n",
    "    for frame in frames:\n",
    "        result.append(cv.GaussianBlur(frame, kernel, 0))\n",
    "    return result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out tracker:\n",
    "\n",
    "\n",
    "'''Testing Frame differencing code based on:\n",
    "https://github.com/infoaryan/OPENCV-PYTHON-Zero-to-One-Course-Resources/blob/master/Video%2031%20-%20Frame%20Differencing/frame_differencing.py\n",
    "Expanded with: blur, dilation and morphological noise reduction and contour finding'''\n",
    "\n",
    "#video to capture\n",
    "\n",
    "video_lst = sorted(video_lst)\n",
    "video = video_lst[5]\n",
    "print(video)\n",
    "\n",
    "kernel = np.ones((7,7)) #kerne for dilation\n",
    "kernel_blur = (3,3)\n",
    "kernel_morph = cv.getStructuringElement(cv.MORPH_ELLIPSE, (7, 7)) #kernel for morphology\n",
    "THRESHOLD = 20 #when to detect difference\n",
    "VALUE = 255 #which value to assign to difference\n",
    "\n",
    "#threshold to calculate\n",
    "threshold_method = cv.THRESH_BINARY\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(video)\n",
    "prev_frame = get_frame(cap)\n",
    "cur_frame = get_frame(cap)\n",
    "#next_frame = get_frame(cap)\n",
    "ret, next_frame = cap.read()\n",
    "\n",
    "print(type(next_frame))\n",
    "\n",
    "centerpoints = []\n",
    "\n",
    "trackerrInit = False\n",
    "\n",
    "\n",
    "# Iterating over all frames and applying difference and dilation\n",
    "while True:\n",
    "    frames = [prev_frame,cur_frame,next_frame]\n",
    "    #applying preprocessing\n",
    "    if type(next_frame) is None:\n",
    "         break\n",
    "    prev_frame, cur_frame, next_frame = prepare_frames(frames, kernel_blur)\n",
    "    \n",
    "    #calculating difference\n",
    "    frame_difference = frame_diff(prev_frame, cur_frame, next_frame)\n",
    "    #cv.imshow('frame diff', frame_difference)\n",
    "    #applying dilation\n",
    "    frame_difference = cv.dilate(frame_difference, kernel)\n",
    "    #applying morphological noise reduction\n",
    "    frame_difference = cv.morphologyEx(frame_difference, cv.MORPH_OPEN, kernel_morph)\n",
    "    #converting into greyscale for contour finding\n",
    "    frame_difference = cv.cvtColor(frame_difference, cv.COLOR_BGR2GRAY)\n",
    "    #applying thresholds\n",
    "    ret, frame_th = cv.threshold(frame_difference, THRESHOLD, VALUE, threshold_method)\n",
    "    #finding and drawing contours on given frame with given threshold\n",
    "    detections = construct_contours(frame_th, 30)\n",
    "    # detections -> bb coordinates\n",
    "    \n",
    "    #cv.imshow(\"Difference\", frame_difference)\n",
    "    cv.imshow(\"After Threshold\", frame_th)\n",
    "    #cv.imshow(\"Frame\", cur_frame)\n",
    "\n",
    "    # if not trackerrInit:\n",
    "    #     # Initialize tracker with first frame and bounding box\n",
    "    #     #tracker.init(cur_frame,)\n",
    "    #     trackerrInit = True\n",
    "\n",
    "\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    #boxes_ids = tracker.update(cur_frame)\n",
    "\n",
    "\n",
    "    # detection\n",
    "    for box_id in boxes_ids:\n",
    "        \n",
    "        x,y,w,h,id = box_id\n",
    "\n",
    "        \n",
    "        # get coordinates of center point\n",
    "        cx = int((x + x + w) / 2)  \n",
    "        cy = int((y + y + h) / 2)\n",
    "        \n",
    "        centerpoints.append((cx, cy))\n",
    "\n",
    "\n",
    "        cv.putText(cur_frame, \"frame:\" + str(cap.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0, 218, 0))\n",
    "        cv.putText(cur_frame,  str(id),(x,y-15), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "        cv.rectangle(cur_frame, (x,y),(x+w, y+h), (0,255,0), 2)\n",
    "        \n",
    "#        for point in centerpoints:\n",
    " #           cv.circle(cur_frame, point, 3, (0,0,255), -1 )\n",
    "        #cv.imshow('frame', cur_frame)\n",
    "\n",
    "    # show circle around centerpoints\n",
    "    for point in centerpoints:\n",
    "        cv.circle(cur_frame, point, 3, (0,0,255), 0 )\n",
    "    cv.imshow('frame', cur_frame)\n",
    "\n",
    "\n",
    "    # Update the variables\n",
    "    prev_frame = cur_frame\n",
    "    cur_frame = next_frame\n",
    "    # next_frame = get_frame(cap)\n",
    "    ret, next_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "         break\n",
    "\n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break    \n",
    "cap.release()\n",
    "cv.waitKey(1)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv.waitKey(1)\n",
    "#cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06845659",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing Frame differencing code based on:\n",
    "https://github.com/infoaryan/OPENCV-PYTHON-Zero-to-One-Course-Resources/blob/master/Video%2031%20-%20Frame%20Differencing/frame_differencing.py\n",
    "Expanded with: blur, dilation and morphological noise reduction and contour finding'''\n",
    "\n",
    "#video to capture\n",
    "video = video_lst[0]\n",
    "print(video)\n",
    "\n",
    "kernel = np.ones((7,7)) #kerne for dilation\n",
    "kernel_blur = (3,3)\n",
    "kernel_morph = cv.getStructuringElement(cv.MORPH_ELLIPSE, (7, 7)) #kernel for morphology\n",
    "THRESHOLD = 20 #when to detect difference\n",
    "VALUE = 255 #which value to assign to difference\n",
    "\n",
    "#threshold to calculate\n",
    "threshold_method = cv.THRESH_BINARY\n",
    "#tracker = EuclideanDistTracker()\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(video)\n",
    "prev_frame = get_frame(cap)\n",
    "cur_frame = get_frame(cap)\n",
    "next_frame = get_frame(cap)\n",
    "\n",
    "\n",
    "\n",
    "# Iterating over all frames and applying difference and dilation\n",
    "while True:\n",
    "    frames = [prev_frame,cur_frame,next_frame]\n",
    "    #applying preprocessing\n",
    "    prev_frame, cur_frame, next_frame = prepare_frames(frames, kernel_blur)\n",
    "    \n",
    "    #calculating difference\n",
    "    frame_difference = frame_diff(prev_frame, cur_frame, next_frame)\n",
    "    #cv.imshow('frame diff', frame_difference)\n",
    "    #applying dilation\n",
    "    frame_difference = cv.dilate(frame_difference, kernel)\n",
    "    #applying morphological noise reduction\n",
    "    frame_difference = cv.morphologyEx(frame_difference, cv.MORPH_OPEN, kernel_morph)\n",
    "    #converting into greyscale for contour finding\n",
    "    frame_difference = cv.cvtColor(frame_difference, cv.COLOR_BGR2GRAY)\n",
    "    #applying thresholds\n",
    "    ret, frame_th = cv.threshold(frame_difference, THRESHOLD, VALUE, threshold_method)\n",
    "    #finding and drawing contours on given frame with given threshold\n",
    "    detections = construct_contours(frame_th, 30)\n",
    "    \n",
    "    \n",
    "    cv.imshow(\"Difference\", frame_difference)\n",
    "    cv.imshow(\"After Threshold\", frame_th)\n",
    "\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    \n",
    "    for box_id in boxes_ids:\n",
    "        x,y,w,h,id = box_id\n",
    "        cv.putText(cur_frame, str(id),(x,y-15), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "        cv.rectangle(cur_frame, (x,y),(x+w, y+h), (0,255,0), 2)\n",
    "        cv.imshow('frame', cur_frame)\n",
    "    \n",
    "    # Update the variables\n",
    "    prev_frame = cur_frame\n",
    "    cur_frame = next_frame\n",
    "    next_frame = get_frame(cap)\n",
    "    \n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break    \n",
    "#cap.release()\n",
    "cv.waitKey(1)\n",
    "cv.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv.waitKey(1)\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "03110c0fd5007860051d23c0250ca1e3b66ec3d524a2182633b6b36ed76114e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
