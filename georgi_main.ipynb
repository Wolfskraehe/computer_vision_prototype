{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bulga\\PycharmProjects\\ComputerVision\\videos/video_005.mp4\n"
     ]
    }
   ],
   "source": [
    "video_path = \"videos\"\n",
    "full_path = os.path.abspath(video_path)\n",
    "\n",
    "video_lst = []\n",
    "v_dir = os.listdir(full_path)\n",
    "for name in v_dir:\n",
    "    video_lst.append(full_path + '/' + name)\n",
    "print(video_lst[5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv.VideoCapture(video_lst[24])\n",
    "# Open the video file\n",
    "video = cap\n",
    "# Set the frame rate\n",
    "\n",
    "\n",
    "# Read the video frame by frame\n",
    "success, frame = video.read()\n",
    "frame_number = 1\n",
    "path = 'C:/Users/bulga/PycharmProjects/ComputerVision/Training Data/45'\n",
    "while success:\n",
    "    # Save the current frame as an image\n",
    "    cv2.imwrite(os.path.join(path, '45{}.jpg'.format(frame_number)), frame)\n",
    "\n",
    "    # Read the next frame\n",
    "    success, frame = video.read()\n",
    "    frame_number += 1\n",
    "\n",
    "# Release the video file\n",
    "video.release()\n",
    "print(frame_number)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m video \u001B[38;5;241m=\u001B[39m \u001B[43mvideo_lst\u001B[49m[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m      3\u001B[0m kernel \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones((\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m7\u001B[39m))  \u001B[38;5;66;03m#kerne for dilation\u001B[39;00m\n\u001B[0;32m      4\u001B[0m kernel_blur \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'video_lst' is not defined"
     ]
    }
   ],
   "source": [
    "video = video_lst[2]\n",
    "\n",
    "kernel = np.ones((7, 7))  #kerne for dilation\n",
    "kernel_blur = (3, 3)\n",
    "kernel_morph = cv.getStructuringElement(cv.MORPH_ELLIPSE, (7, 7))  #kernel for morphology\n",
    "THRESHOLD = 20  #when to detect difference\n",
    "VALUE = 255  #which value to assign to difference\n",
    "\n",
    "#threshold to calculate\n",
    "threshold_method = cv.THRESH_BINARY\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "\n",
    "# Compute the frame difference\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    diff_frames1 = cv.absdiff(next_frame, cur_frame)\n",
    "    # Absolute difference between current frame and previous frame\n",
    "    diff_frames2 = cv.absdiff(cur_frame, prev_frame)\n",
    "    # Return the result of bitwise 'AND' between the above two resultant images\n",
    "    #gives better result than simple substraction\n",
    "    return cv.bitwise_and(diff_frames1, diff_frames2)\n",
    "\n",
    "\n",
    "def get_frame(cap):\n",
    "    ret, frame = cap.read()\n",
    "    # Resize the image not needed\n",
    "    '''frame = cv.resize(frame, None, fx=scaling_factor,\n",
    "        fy=scaling_factor, interpolation=cv.INTER_AREA)'''\n",
    "    return frame\n",
    "\n",
    "\n",
    "#finds and draws contours over pixels if greater than threshold\n",
    "def construct_contours(frame, contour_threshold):\n",
    "    frame = cv.dilate(frame, (1, 1), iterations=1)\n",
    "    contours, hierarchy = cv.findContours(frame, cv.RETR_TREE,\n",
    "                                          cv.CHAIN_APPROX_SIMPLE)\n",
    "    '''cv.drawContours(frame_th, contours=contours, contourIdx=-1,\n",
    "                     color=(0, 255, 0), thickness=2, lineType=cv.LINE_AA)'''\n",
    "    detections = []\n",
    "    for contour in contours:\n",
    "        if cv.contourArea(contour) < contour_threshold:\n",
    "            continue\n",
    "        (x, y, w, h) = cv.boundingRect(contour)\n",
    "        #cv.rectangle(frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "        detections.append([x, y, w, h])\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(video)\n",
    "prev_frame = get_frame(cap)\n",
    "cur_frame = get_frame(cap)\n",
    "next_frame = get_frame(cap)\n",
    "\n",
    "model = load_model('multiclass_recognition.h5')\n",
    "\n",
    "\n",
    "#applying blur will possibly extend with other option for preperation\n",
    "def prepare_frames(frames, kernel):\n",
    "    result = []\n",
    "    for frame in frames:\n",
    "        result.append(cv.GaussianBlur(frame, kernel, 0))\n",
    "    return result[0], result[1], result[2]\n",
    "\n",
    "frame_number=0\n",
    "\n",
    "# Iterating over all frames and applying difference and dilation\n",
    "while True:\n",
    "    frames = [prev_frame, cur_frame, next_frame]\n",
    "\n",
    "    frame_number += 1\n",
    "\n",
    "    # check if we need to make a prediction\n",
    "    if frame_number % 30 == 0:\n",
    "        img = cur_frame\n",
    "        res = cv2.resize(img, dsize=(256, 256))\n",
    "        x = np.asarray(res)\n",
    "\n",
    "        # reshape the array\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        # make a prediction on the image\n",
    "        prediction = model.predict(x)\n",
    "        thr = [20, 25, 30, 45]\n",
    "        class_index = np.argmax(prediction)\n",
    "\n",
    "\n",
    "        THRESHOLD = thr[class_index]\n",
    "        print(thr[class_index])\n",
    "    real_frame = cur_frame\n",
    "    #applying preprocessing\n",
    "    prev_frame, cur_frame, next_frame = prepare_frames(frames, kernel_blur)\n",
    "    #cv.imshow(\"cur_frame\", cur_frame)\n",
    "    #calculating difference\n",
    "    frame_difference = frame_diff(prev_frame, cur_frame, next_frame)\n",
    "    #cv.imshow(\"Difference\", frame_difference)\n",
    "    #applying dilation\n",
    "    frame_difference = cv.dilate(frame_difference, kernel)\n",
    "    #cv.imshow(\"dilate\", frame_difference)\n",
    "    #applying morphological noise reduction\n",
    "    frame_difference = cv.morphologyEx(frame_difference, cv.MORPH_OPEN, kernel_morph)\n",
    "    #cv.imshow(\"morphologyEx\", frame_difference)\n",
    "\n",
    "    #converting into greyscale for contour finding\n",
    "    frame_difference = cv.cvtColor(frame_difference, cv.COLOR_BGR2GRAY)\n",
    "    #cv.imshow(\"cvtColor\", frame_difference)\n",
    "    #applying thresholds\n",
    "    ret, frame_th = cv.threshold(frame_difference, THRESHOLD, VALUE, threshold_method)\n",
    "    #cv.imshow(\"threshold\", frame_difference)\n",
    "    #finding and drawing contours on given frame with given threshold\n",
    "    detections = construct_contours(frame_th, 30)\n",
    "\n",
    "    #cv.imshow(\"Difference\", frame_difference)\n",
    "    cv.imshow(\"After Threshold\", frame_th)\n",
    "\n",
    "    boxes_ids = tracker.update(detections)\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        cv.putText(real_frame, str(id), (x, y - 15), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv.rectangle(real_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv.imshow('frame', real_frame)\n",
    "\n",
    "    # Update the variables\n",
    "    prev_frame = cur_frame\n",
    "    cur_frame = next_frame\n",
    "    next_frame = get_frame(cap)\n",
    "\n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
