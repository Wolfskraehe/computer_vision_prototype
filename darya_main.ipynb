{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b8b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc5dbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daryashitova/Documents/MA_AI/WS22:23/Computer Vision/project/videos/video_026.mp4\n"
     ]
    }
   ],
   "source": [
    "'''loading video names into a list for easier access with absolute path,\n",
    "video names can be access by calling the index of the video_lst and will contain \n",
    "the current absolute path, asumes that the video folder is in the same folder as this file'''\n",
    "\n",
    "video_path = \"../videos\"\n",
    "full_path = os.path.abspath(video_path)\n",
    "\n",
    "video_lst = []\n",
    "v_dir = os.listdir(full_path)\n",
    "for name in v_dir:\n",
    "    video_lst.append(full_path+'/'+name)\n",
    "print(video_lst[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e7eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading video into memory\n",
    "cap = cv.VideoCapture(video_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc52016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daryashitova/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "class CentroidTracker():\n",
    "\tdef __init__(self, maxDisappeared=50):\n",
    "\t\t# initialize the next unique object ID along with two ordered\n",
    "\t\t# dictionaries used to keep track of mapping a given object\n",
    "\t\t# ID to its centroid and number of consecutive frames it has\n",
    "\t\t# been marked as \"disappeared\", respectively\n",
    "\t\tself.nextObjectID = 0\n",
    "\t\tself.objects = OrderedDict()\n",
    "\t\tself.disappeared = OrderedDict()\n",
    "\t\t# store the number of maximum consecutive frames a given\n",
    "\t\t# object is allowed to be marked as \"disappeared\" until we\n",
    "\t\t# need to deregister the object from tracking\n",
    "\t\tself.maxDisappeared = maxDisappeared\n",
    "\n",
    "\tdef register(self, centroid):\n",
    "\t\t# when registering an object we use the next available object\n",
    "\t\t# ID to store the centroid\n",
    "\t\tself.objects[self.nextObjectID] = centroid\n",
    "\t\tself.disappeared[self.nextObjectID] = 0\n",
    "\t\tself.nextObjectID += 1\n",
    "\n",
    "\tdef deregister(self, objectID):\n",
    "\t\t# to deregister an object ID we delete the object ID from\n",
    "\t\t# both of our respective dictionaries\n",
    "\t\tdel self.objects[objectID]\n",
    "\t\tdel self.disappeared[objectID]\n",
    "\n",
    "\tdef update(self, rects):\n",
    "\t\t# check to see if the list of input bounding box rectangles\n",
    "\t\t# is empty\n",
    "\t\tif len(rects) == 0:\n",
    "\t\t\t# loop over any existing tracked objects and mark them\n",
    "\t\t\t# as disappeared\n",
    "\t\t\tfor objectID in list(self.disappeared.keys()):\n",
    "\t\t\t\tself.disappeared[objectID] += 1\n",
    "\t\t\t\t# if we have reached a maximum number of consecutive\n",
    "\t\t\t\t# frames where a given object has been marked as\n",
    "\t\t\t\t# missing, deregister it\n",
    "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
    "\t\t\t\t\tself.deregister(objectID)\n",
    "\t\t\t# return early as there are no centroids or tracking info\n",
    "\t\t\t# to update\n",
    "\t\t\treturn self.objects\n",
    "\t\t# initialize an array of input centroids for the current frame\n",
    "\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\t\t# loop over the bounding box rectangles\n",
    "\t\tfor (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "\t\t\t# use the bounding box coordinates to derive the centroid\n",
    "\t\t\tcX = (startX + startX + endX) // 2.0\n",
    "\t\t\tcY = (startY + startY + endY) // 2.0\n",
    "\t\t\tinputCentroids[i] = (cX, cY)\n",
    "\t\t# if we are currently not tracking any objects take the input\n",
    "\t\t# centroids and register each of them\n",
    "\t\tif len(self.objects) == 0:\n",
    "\t\t\tfor i in range(0, len(inputCentroids)):\n",
    "\t\t\t\tself.register(inputCentroids[i])\n",
    "\t\t# otherwise, are are currently tracking objects so we need to\n",
    "\t\t# try to match the input centroids to existing object\n",
    "\t\t# centroids\n",
    "\t\telse:\n",
    "\t\t\t# grab the set of object IDs and corresponding centroids\n",
    "\t\t\tobjectIDs = list(self.objects.keys())\n",
    "\t\t\tobjectCentroids = list(self.objects.values())\n",
    "\t\t\t# compute the distance between each pair of object\n",
    "\t\t\t# centroids and input centroids, respectively -- our\n",
    "\t\t\t# goal will be to match an input centroid to an existing\n",
    "\t\t\t# object centroid\n",
    "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\t\t\t# in order to perform this matching we must (1) find the\n",
    "\t\t\t# smallest value in each row and then (2) sort the row\n",
    "\t\t\t# indexes based on their minimum values so that the row\n",
    "\t\t\t# with the smallest value is at the *front* of the index\n",
    "\t\t\t# list\n",
    "\t\t\trows = D.min(axis=1).argsort()\n",
    "\t\t\t# next, we perform a similar process on the columns by\n",
    "\t\t\t# finding the smallest value in each column and then\n",
    "\t\t\t# sorting using the previously computed row index list\n",
    "\t\t\tcols = D.argmin(axis=1)[rows]\n",
    "\t\t\t# in order to determine if we need to update, register,\n",
    "\t\t\t# or deregister an object we need to keep track of which\n",
    "\t\t\t# of the rows and column indexes we have already examined\n",
    "\t\t\tusedRows = set()\n",
    "\t\t\tusedCols = set()\n",
    "\t\t\t# loop over the combination of the (row, column) index\n",
    "\t\t\t# tuples\n",
    "\t\t\tfor (row, col) in zip(rows, cols):\n",
    "\t\t\t\t# if we have already examined either the row or\n",
    "\t\t\t\t# column value before, ignore it\n",
    "\t\t\t\t# val\n",
    "\t\t\t\tif row in usedRows or col in usedCols:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t# otherwise, grab the object ID for the current row,\n",
    "\t\t\t\t# set its new centroid, and reset the disappeared\n",
    "\t\t\t\t# counter\n",
    "\t\t\t\tobjectID = objectIDs[row]\n",
    "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
    "\t\t\t\tself.disappeared[objectID] = 0\n",
    "\t\t\t\t# indicate that we have examined each of the row and\n",
    "\t\t\t\t# column indexes, respectively\n",
    "\t\t\t\tusedRows.add(row)\n",
    "\t\t\t\tusedCols.add(col)\n",
    "\t\t\t# compute both the row and column index we have NOT yet\n",
    "\t\t\t# examined\n",
    "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\t\t\t# in the event that the number of object centroids is\n",
    "\t\t\t# equal or greater than the number of input centroids\n",
    "\t\t\t# we need to check and see if some of these objects have\n",
    "\t\t\t# potentially disappeared\n",
    "\t\t\tif D.shape[0] >= D.shape[1]:\n",
    "\t\t\t\t# loop over the unused row indexes\n",
    "\t\t\t\tfor row in unusedRows:\n",
    "\t\t\t\t\t# grab the object ID for the corresponding row\n",
    "\t\t\t\t\t# index and increment the disappeared counter\n",
    "\t\t\t\t\tobjectID = objectIDs[row]\n",
    "\t\t\t\t\tself.disappeared[objectID] += 1\n",
    "\t\t\t\t\t# check to see if the number of consecutive\n",
    "\t\t\t\t\t# frames the object has been marked \"disappeared\"\n",
    "\t\t\t\t\t# for warrants deregistering the object\n",
    "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
    "\t\t\t\t\t\tself.deregister(objectID)\n",
    "\t\t\t# otherwise, if the number of input centroids is greater\n",
    "\t\t\t# than the number of existing object centroids we need to\n",
    "\t\t\t# register each new input centroid as a trackable object\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor col in unusedCols:\n",
    "\t\t\t\t\tself.register(inputCentroids[col])\n",
    "\t\t# return the set of trackable objects\n",
    "\t\treturn self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750879ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "# Compute the frame difference\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    diff_frames1 = cv.absdiff(next_frame, cur_frame)\n",
    "    # Absolute difference between current frame and previous frame\n",
    "    diff_frames2 = cv.absdiff(cur_frame, prev_frame)\n",
    "    # Return the result of bitwise 'AND' between the above two resultant images\n",
    "    #gives better result than simple substraction\n",
    "    return cv.bitwise_and(diff_frames1, diff_frames2)\n",
    "\n",
    "def get_frame(cap):\n",
    "    ret, frame = cap.read()\n",
    "    # Resize the image not needed\n",
    "    '''frame = cv.resize(frame, None, fx=scaling_factor,\n",
    "        fy=scaling_factor, interpolation=cv.INTER_AREA)'''\n",
    "    return frame\n",
    "\n",
    "#finds and draws contours over pixels if greater than threshold\n",
    "def construct_contours(frame, contour_threshold):\n",
    "    frame = cv.dilate(frame, (1,1), iterations=1)\n",
    "    contours, hierarchy = cv.findContours(frame, cv.RETR_TREE, \n",
    "                                           cv.CHAIN_APPROX_SIMPLE)\n",
    "    '''cv.drawContours(frame_th, contours=contours, contourIdx=-1, \n",
    "                     color=(0, 255, 0), thickness=2, lineType=cv.LINE_AA)'''\n",
    "    detections=[]\n",
    "    for contour in contours:\n",
    "      if cv.contourArea(contour) < contour_threshold:\n",
    "        continue\n",
    "      (x, y, w, h) = cv.boundingRect(contour)\n",
    "      #cv.rectangle(frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "      detections.append([x,y,w,h])\n",
    "    \n",
    "    return detections\n",
    "\n",
    "    #applying blur will possibly extend with other option for preperation\n",
    "def prepare_frames(frames,kernel):\n",
    "    result = []\n",
    "    for frame in frames:\n",
    "        result.append(cv.GaussianBlur(frame, kernel, 0))\n",
    "    return result[0], result[1], result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0437e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "'''Frame differencing code based on:\n",
    "https://github.com/infoaryan/OPENCV-PYTHON-Zero-to-One-Course-Resources/blob/master/Video%2031%20-%20Frame%20Differencing/frame_differencing.py\n",
    "Expanded with: blur, dilation and morphological noise reduction and contour finding\n",
    "\n",
    "Threshold for noise reduction and contour finding is adapted dynamically and will be \n",
    "calculated in every frame\n",
    "'''\n",
    "\n",
    "#video to capture\n",
    "video = sorted(video_lst)[0]\n",
    "\n",
    "kernel = np.ones((7,7)) #kerne for dilation, erosion\n",
    "kernel_blur = (3,3)\n",
    "kernel_morph = cv.getStructuringElement(cv.MORPH_ELLIPSE, (7, 7)) #kernel for morphology\n",
    "threshold = 0 #when to detect difference\n",
    "VALUE = 255 #which value to assign to difference\n",
    "frame_counter = 0\n",
    "power = 1 #magnifying factor for adaptive threshold\n",
    "\n",
    "#threshold to calculate\n",
    "threshold_method = cv.THRESH_BINARY\n",
    "tracker = CentroidTracker()\n",
    "centerpoints = []\n",
    "\n",
    "# Compute the frame difference\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    diff_frames1 = cv.absdiff(next_frame, cur_frame)\n",
    "    # Absolute difference between current frame and previous frame\n",
    "    diff_frames2 = cv.absdiff(cur_frame, prev_frame)\n",
    "    # Return the result of bitwise 'AND' between the above two resultant images\n",
    "    #gives better result than simple substraction\n",
    "    return cv.bitwise_and(diff_frames1, diff_frames2)\n",
    "\n",
    "def get_frame(cap):\n",
    "    ret, frame = cap.read()\n",
    "    # Resize the image if convolution made the tracking area smaller\n",
    "    '''frame = cv.resize(frame, None, fx=1,\n",
    "        fy=1, interpolation=cv.INTER_AREA)'''\n",
    "    return frame\n",
    "\n",
    "#finds and draws contours over pixels if greater than threshold\n",
    "def construct_contours(frame, contour_threshold):\n",
    "    #frame = cv.dilate(frame, (1,1), iterations=1)\n",
    "    contours, hierarchy = cv.findContours(frame, cv.RETR_TREE, \n",
    "                                           cv.CHAIN_APPROX_SIMPLE)\n",
    "    '''cv.drawContours(frame_th, contours=contours, contourIdx=-1, \n",
    "                     color=(0, 255, 0), thickness=2, lineType=cv.LINE_AA)'''\n",
    "    detections=[]\n",
    "    for contour in contours:\n",
    "      if cv.contourArea(contour) < contour_threshold:\n",
    "        continue\n",
    "      (x, y, w, h) = cv.boundingRect(contour)\n",
    "      #cv.rectangle(frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)\n",
    "      detections.append([x,y,w,h])\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "cap =cv.VideoCapture(video)\n",
    "prev_frame = get_frame(cap)\n",
    "cur_frame = get_frame(cap)\n",
    "next_frame = get_frame(cap)\n",
    "\n",
    "tracks = {}\n",
    "\n",
    "'''Check if directory exists, if not, create it'''\n",
    "import os\n",
    "\n",
    "# You should change 'test' to your preferred folder.\n",
    "dir = (\"outputs\")\n",
    "check = os.path.isdir(dir)\n",
    "# If folder doesn't exist, then create it.\n",
    "if not check:\n",
    "    os.makedirs(dir)\n",
    "\n",
    "file_name = video.split(\"/\")[-1].split(\".\")\n",
    "file_name[0] = file_name[0]+\"_out\"\n",
    "output_name = \".\".join(file_name)\n",
    "full_output_path = f\"{dir}/{output_name}\"\n",
    "\n",
    "result = cv.VideoWriter(full_output_path, cv.VideoWriter_fourcc(*'XVID'), 20, (640, 512))\n",
    "\n",
    "\n",
    "#applying blur will possibly extend with other option for preperation\n",
    "def prepare_frames(frames,kernel):\n",
    "    result = []\n",
    "    for frame in frames:\n",
    "        result.append(cv.GaussianBlur(frame, kernel, 0))\n",
    "    return result[0], result[1], result[2]\n",
    "\n",
    "# Iterating over all frames and applying difference and dilation\n",
    "while True:\n",
    "    frames = [prev_frame,cur_frame,next_frame]\n",
    "    frame_counter += 1\n",
    "    #applying preprocessing\n",
    "    prev_frame, cur_frame, next_frame = prepare_frames(frames, kernel_blur)\n",
    "    \n",
    "    #cv.imshow(\"Blur\", cur_frame)\n",
    "    #calculating difference\n",
    "    frame_difference = frame_diff(prev_frame, cur_frame, next_frame)\n",
    "    #cv.imshow(\"Difference\", frame_difference)\n",
    "   \n",
    "    #applying dilation\n",
    "    frame_difference = cv.erode(frame_difference, (1,1))\n",
    "    frame_difference = cv.dilate(frame_difference, kernel)\n",
    "    #cv.imshow(\"Dilation\", frame_difference)\n",
    "    \n",
    "    #applying morphological noise reduction\n",
    "    frame_difference = cv.morphologyEx(frame_difference, cv.MORPH_OPEN, kernel_morph)\n",
    "    #cv.imshow(\"Morph\", frame_difference)\n",
    "   \n",
    "    #grayscale conversion\n",
    "    frame_difference = cv.cvtColor(frame_difference, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    #applying thresholds\n",
    "    ret, frame_th = cv.threshold(frame_difference, threshold, VALUE, threshold_method)\n",
    "    #cv.imshow(\"Threshold\", frame_difference)\n",
    "    \n",
    "    #finding and drawing contours on given frame with given threshold\n",
    "    detections = construct_contours(frame_th, threshold)\n",
    "    #cv.imshow(\"Contours\", detections)\n",
    "    #cv.imshow(\"Difference\", frame_difference)\n",
    "    #cv.imshow(\"After Threshold\", frame_th)\n",
    "    #frame_difference_blured = cv.medianBlur(frame_difference,7)\n",
    "    \n",
    "    frame_difference_blured = cv.blur(frame_difference,(10,10)) # needed for adapting threshold\n",
    "    \n",
    "    '''Dynamic threshold adaption'''\n",
    "    threshold_new = np.quantile(frame_difference_blured, 0.9999)\n",
    "    frame_skip = 1#how many frames to skip\n",
    "    \n",
    "    if frame_counter == 1:\n",
    "        threshold = threshold_new\n",
    "    if frame_counter % frame_skip == 0: \n",
    "        if threshold_new > 0.995**power * threshold:\n",
    "            threshold = threshold_new\n",
    "            power = 1\n",
    "        if threshold_new <= 0.995**power * threshold:\n",
    "            power += 1\n",
    "    \n",
    "\n",
    "    if frame_counter > 10:\n",
    "        boxes_ids = tracker.update(detections)\n",
    "        for (objectID, centroid) in boxes_ids.items():\n",
    "            if objectID in tracks:\n",
    "                tracks[objectID].append(centroid)\n",
    "            else:\n",
    "                tracks[objectID] = [centroid]\n",
    "            \n",
    "            centerpoints.append((centroid[0], centroid[1]))\n",
    "            text = f\"ID {objectID}\"\n",
    "\n",
    "            cv.putText(cur_frame, text, (centroid[0], centroid[1]-15),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0, 255, 0), 2)\n",
    "            #cv.putText(cur_frame,  str(id),(x,y-15), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "            cv.rectangle(cur_frame, (centroid[0]-10, centroid[1]-10), (centroid[0]+10, centroid[1]+10), (0,255,0), 2)\n",
    "\n",
    "            \n",
    "        for key in tracks:\n",
    "            for i, point in enumerate(tracks[key][1:]):\n",
    "                cv.line(cur_frame, tracks[key][i], point, (0,255,0), 3) \n",
    "\n",
    "    result.write(cur_frame)\n",
    "    # Update the variables\n",
    "    prev_frame = cur_frame\n",
    "    cur_frame = next_frame\n",
    "    # next_frame = get_frame(cap)\n",
    "    ret, next_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break    \n",
    "cap.release()\n",
    "result.release()\n",
    "cv.waitKey(1)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "for i in range (1,5):\n",
    "    cv.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "136c3a30a264eb8837c5428b8ac2f763a13089617e3218cb4fc861e953197bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
